\documentclass[10pt,a4paper,titlepage]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{makeidx}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage[hidelinks]{hyperref}

%this is a command used in the title template
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

%questo fa in modo che le liste numerate siano allineate come le altre
\setenumerate{leftmargin=*, labelindent=\parindent}

%questo genera il toc, ricorda di eseguire due volte
\makeindex

\begin{document}
\input{title.tex}

\tableofcontents

\pagebreak
\part{Introduction}
In the following document we analyze our project using two different approaches.  
In the first part we apply the Function Point approach in order to check whether the result is 
similar to the actual size of the project. 
In the second part we apply COCOMO formulas and compare the results with the the ``real'' 
effort spent to develop the project.  

\section{Size of the project}
To perform the mentioned analysis we need to know the actual size of the project.  
In order to compute the number of lines of code (LOC) we used a plugin for NetBeans called 
Simple Code Metrics. 
Using this tool we computed an actual size of 4372 LOC. 
This number does not take into account the xhtml pages. Obviously we didn't take into consideration the lines of comments and testdrivers.
 
\section{Overall project time}
COCOMO II provides an estimation of the overall effort needed to develop the project.  
We want to make a comparison between the estimation and the actual time needed by the 
team to accomplish the task. 
In order to do so we kept track of the time each member of the team spent on the project. 
\begin{enumerate}
\item $T_{RASD} = 30h+30h=60h$
\item $T_{DD} = 30h+35h=65h$
\item $T_{DEV} = 150h+150h=300h$
\end{enumerate}
The overall time spent by the two members of the team on the project turns out to be:

$T_{TOT} = T_{RASD}+T_{DD}+T_{DEV} = 60h+65h+300h = 425h$
 
\pagebreak
\part{Function point}
In order to determine the number of LOC (lines of code) of the project we first have to find out 
the number of Functions Points (FP) that have to be addressed.  

\begin{enumerate}
\item Internal Logical Files (ILF)

\begin{enumerate}
\item  The system has to store information about the user and his/her participations.

Weight: \textit{medium}

The complexity is medium for the following reasons:
\begin{itemize}
\item The ``users'' table contains several fields
\item The system has to manage security settings for the account (i.e. passwords have to be encrypted and stored securely)  
\item A user calendar may contain a high number of events 
\end{itemize}

\item The system has to store events

Weight: \textit{medium}

The medium weight has been chosen because the ``event'' table has to contain several different fields. 

\item The system has to store notification 

Weight: \textit{simple }

The simple weight has been chosen because notifications are quite simple entities (with a small number of parameters). 
\end{enumerate}

\item External Interface Files (EIF)
\begin{enumerate}
\item The system has to retrieve and store forecast's data 
 
Weight: \textit{complex }
 
The weight is complex because the management of external forecasts' data requires parsing information coming from the external service and the handling of two different kind of forecasts: daily and 3 hours.
 
\item The system has to store a list of available places and their information 
 
Weight: \textit{simple }
 
The system has just to download the list of places at the startup of the server. 
\end{enumerate}

\item External Inputs (EI)
\begin{enumerate}
\item Login and Logout 
 
Weight: \textit{simple}
 
These operations are very straightforward. They only involve checking the correspondence between username and password and eventually shutting down the session. 
 
\item Registration 
 
Weight: \textit{simple}
 
These operation consists only in inserting a new tuple in the user table while performing some basic checks on the input values. 

\item Change personal settings 
 
Weight: \textit{simple}

These operation consists only in updating a tuple in the user table while performing some basic checks on the input values. 
 
\item Event creation, modification

Weight: \textit{complex}

These operations involves the insert/update of a tuple in the event
table. Quite complex issues arise because the system has to take care 
of different roles of users (i.e. When the creator of an event modifies it 
all the participants has to be informed of that and their calendar have to 
be updated) 
 
\item  Search users 
 
Weight: \textit{simple }

The system has just to perform some queries (addressing the user 
table) to retrieve the list of users corresponding to the specified 
search key. 
 
\item Answer to notifications 

Weight: \textit{complex}

After the user answers a notification the system has to take care of the 
update of several different tables. 
\end{enumerate}

\item External Inquiries (EI)
\begin{enumerate}
\item Show ``about page''
 
Weight: \textit{simple}

The system has only to display a description of MeteoCal in order to 
inform a new user of its functionalities. 
 
\item Browse personal calendar 
 
Weight: \textit{simple}

The system retrieves events in which the user will take part and 
displays them.  
 
\item Browse external calendars 
Weight: \textit{medium}
 
The system has to take care of privacy settings for both users' calendar 
and their events. It has to display the ``external'' calendar and its events 
according to the user's settings. 
\end{enumerate}

\item External Outputs (EO)
\begin{enumerate}
\item Display weather forecasts 
 
Weight: \textit{complex}

The system has to manage the interaction with the external service 
providing the forecasts. Moreover it has to periodically update them. 
 
\item Display notifications 

Weight: \textit{complex}

The system has to detect various types of changes in the events details 
and generate notifications for the interested users accordingly. Thus 
several tables of the database are involved. 
\end{enumerate}
\end{enumerate}

 
To calculate the LOC estimate we will use the following table of weights:

\begin{center}\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Function types} & \multicolumn{3}{|c|}{\textbf{Weights}} \\
\hline				&	Simple	&	Medium	& Complex	\\
\hline	N.Inputs	&	3		&	4		&	6		\\
\hline	N.Outputs	&	4		&	5		&	7		\\
\hline	N.Inquiry	&	3		&	4		&	6		\\
\hline	N.ILF		&	7		&	10		&	15		\\
\hline	N.EIF		&	5		&	7		&	10		\\
\hline\end{tabular}\end{center}

The Unadjust Function Point (UFP) is the result of the following contributes: 
\begin{itemize}
\item $\textbf{ILF} = 1*simple+2*medium=7+10+10=27$

\item $\textbf{EIF} = 1*simple+1*complex=5+10=15$

\item $\textbf{EI\hspace{7pt}} = 4*simple+2*complex=4*3+2*6=24$

\item $\textbf{EIQ} = 2*simple+1*medium=2*3+1*4=10$

\item $\textbf{EO\hspace{5pt}} = 2*complex=2*7=14$
\end{itemize}

$\textbf{UFP} = 27+15+24+0+14 = 90 {FPs}$

In order to obtain the estimation of the lines of code we have to use the following simple formula:

\[LOC= AVG * UFP\]
 
Where AVG is a language dependent factor.
We use the AVG specific for J2EE, which is the programming language mainly used to develop the project. The coefficient was taken from: \url{http://www.qsm.com/resources/function-point-languages-table} (we used the value in the Avg column) 
 
 
The final estimation turns out to be: 

\[LOC = 46*90=4140\]
 
Given an actual size of 4372 LOC the estimation turns out to be really precise.  
There is a difference of just 232 lines, which is the 5,3\% of the total real size. 

\pagebreak
\part{COCOMO II}
(For this analysis we referred to the “COCOMO II Model Definition Manual” (version 2.1) available at: \url{http://csse.usc.edu/csse/research/COCOMOII/cocomo_downloads.html})

In COCOMO II effort is expressed as Person-Months (PM). The effort is computed as follows:

\[PM = A * Size^E * \prod\limits_{i=1}^n {EM_i}\]
\begin{center}where $A=2.94$ (for COCOMO II.2000\end{center}

The Size is expressed in KSLOC. This is derived from estimating the size of software modules that will constitute the application program.  
 
The way in which the exponent E and the effort multipliers (EM) are calculated and their meaning are explained in the following sections. 

\section{Exponent}
The exponent E is an aggregation of five scale factors (SF) that account for the relative economies or diseconomies of scale encountered for software projects of different sizes:
\begin{itemize}
\item If $E < 1.0$, the project exhibits economies of scale.
\item If $E = 1.0$, the economies and diseconomies of scale are in balance.
\item If $E > 1.0$, the project exhibits diseconomies of scale.
\end{itemize}

The exponent E is calculated as follows:
\[E = B + 0.01 * \sum\limits_{j=1}^5{SF_j}\]
\begin{center}
where $B=0.91$ (for COCOMO II.2000)
\end{center}

Each scale factors has a range of rating levels, from Very Low to Extra High. Each rating level has a weight. The specific value of the weight is called a scale factor (SF). The project's scale factors, the selected scale factors ratings, are summed and used to determine a scale exponent.

We used the following table to retrieve weights:

\noindent\hspace*{-50pt}\begin{tabular}{|p{0.15\linewidth}|p{0.15\linewidth}|p{0.15\linewidth}|p{0.15\linewidth}|p{0.15\linewidth}|p{0.15\linewidth}|p{0.15\linewidth}|}
\hline 
Scale Factors & Very Low & Low & Nominal & High & Very High  & Extra High \\ 
\hline 
PREC & thoroughly unprecedented & largely unprecedented & somewhat unprecedented & generally familiar & largely familiar & thoroughly familiar \\ 
$SF_i$ & 6.20 & 4.96 & 3.72 & 2.48 & 1.24 & 0.00 \\

\hline 
FLEX & rigorous & occasional relaxation & some relaxation & general conformity & some conformity & general goals \\ 
$SF_i$ & 5.07 & 4.05 & 3.04 & 2.03 & 1.01 & 0.00 \\ 

\hline 
RESL & little (20\%) & some (40\%) & often (60\%) & generally (75\%) & mostly (90\%) & full (100\%) \\ 
$SF_i$ & 7.07 & 5.65 & 4.24 & 2.83 & 1.41 & 0.00 \\

\hline 
TEAM & very difficult interactions & some difficult interactions & basically cooperative interactions & largely cooperative & highly cooperative & seamless interactions \\ 
$SF_i$ & 5.48 & 4.38 & 3.29 & 2.19 & 1.10 & 0.00 \\

\hline 
PMAT & \multicolumn{6}{|c|}{The estimated Process Maturity Level (EPML) or:}\\
\cline{2-7}
 & SW-CMM Level 1 Lower & SW-CMM Level 1 Upper & SW-CMM Level 2 & SW-CMM Level 3 & SW-CMM Level 4 & SW-CMM Level 5 \\
$SF_i$ & 7.80 & 6.24 & 4.68 & 3.12 & 1.56 & 0.00 \\
\hline 
\end{tabular}

\vspace{10pt}
This is the list of appropriate scale factors rating levels for our project:
\begin{enumerate}
\item Precedentedness (PREC)

Rating level: \textit{nominal}

The team never developed a web-based project and did not have any experience with the J2EE environment, but had some previous experience on Java developing.

\item Development Flexibility (FLEX)

rating Level: \textit{high}

The only constraints we had were on the language to be used and on functional requirement that the system had to fulfill. 

\item Architecture / Risk Resolution (RESL)

Rating level: \textit{nominal}

We devoted quite a lot of time to establish the system architecture given the general product objective. Nevertheless it was difficult to predict risks since the environment was new and we couldn't rely on previous experience.

\item Team Cohesion (TEAM)

Rating level: \textit{very high}

Stakeholders had shared objectives and were committed to reach them. The team had already worked on other projects and so it was rather easy to organize the work. We only had some minor ``communication issues'', for this reason the lever is \textit{very high} and not \textit{extra high}.

\item Process Maturity (PMAT)

Rating level: \textit{nominal}

We chose level 2 because processes have been planned and documented at the project level.
\end{enumerate}

Having chosen the rating levels for each scale factor we can now calculate the exponent:

\[E=0.91+0.01*(3.72+2.03+4.24+1.1+4.68)=1.0677\]

The exponent shows that economies and dis-economies of scales are almost in balance. This is mainly due to the fact that, despite the lack of previous experience, the team was small and easy to organize.

\section{Effort Adjustment Factor}
The seventeen effort multipliers (EM) are used in the COCOMO II model to adjust the nominal effort, Person-Months, to reflect the software product under development.
 
Each multiplicative cost driver is defined below by a rating level and a corresponding  effort multiplier (the values are taken from the document referenced at the beginning of this part).  
 
\begin{enumerate}
\item Required Software Reliability (RELY)

Rating level: \textit{low}

Effort multiplier: 0.92

Software failures give rise to easily recoverable losses. There are neither financial losses nor risk for human life.

\item Data Base Size (DATA) 
Rating level: \textit{low}

Effort multiplier: 0,9 
 
We tested the system without the need of huge testing data sets.

\item Product Complexity (CPLX) 
Rating level: \textit{low}

Effort multiplier: 0,87 
 
Considering all the different parts of the system (including the gui and the data management system) the overall complexity was modest if compared with industry standards. 
 
\item Developed for Reusability (RUSE)

Rating level: \textit{nominal}

Effort multiplier: 1,00 
 
The reusability focus was across project. We designed project's components to be easily reusable.  

\item Documentation match to lifecycle needs (DOCU)

Rating level: \textit{nominal}

Effort multiplier: 1,00 
 
The documentation covers the basic needs of the project. The requirements analysis and the design document are complete and detailed. 
 
\item Execution Time Constraint (TIME)  

Rating level: \textit{nominal}

Effort multiplier: 1,00 
 
The system didn't require high execution time to perform complex tasks. 
 
\item Main Storage Constraint (STOR) 

Rating level: \textit{nominal}

Effort multiplier: 1,00 
 
The system used less (way less) of the 50\% of available storage space. 
 
\item Platform Volatility (PVOL)

Rating level: \textit{low}

Effort multiplier: 0,87 
 
The development environment and the used tools didn’t change significantly 
during our work. 
 
\item Analyst Capability (ACAP) 

Rating level: \textit{high}

Effort multiplier: 0,85 
 
The team had good design ability and was able to efficiently cooperate in the analysis of the project. 
 
\item Programmer Capability (PCAP) 

Rating level: \textit{high}

Effort multiplier: 0,88 
 
The team was able to efficiently make use of members' programming skills with a good organization of the work. 

\item Personnel Continuity (PCON) 

Rating level: \textit{very high}

Effort multiplier: 0,81 
 
The team didn't undergo any personnel turnover. 
 
\item Applications Experience (APEX) 

Rating level: \textit{very low}

Effort multiplier: 1,22 

The team experience in developing applications of this kind was less than 2 month (this type of application was completely new to us). 
 
\item Platform Experience (PLEX) 

Rating level: \textit{very low}

Effort multiplier: 1,19 
 
The considered platform was completely new to the team. 

\item Language and Tool Experience (LTEX) 

Rating level: \textit{nominal}

Effort multiplier: 1,00 
 
The programming language that has been mainly used is Java. Both team members have an experience with this programming language that is between 1 and 2 years. 
 
\item Use of Software Tools (TOOL) 

Rating level: \textit{nominal}

Effort multiplier: 1,00 
 
The team utilized basic lifecycle tools with which was already experienced (we used similar tools in the Software Engineering 1 course the last year). 

\item Multisite Development (SITE) 

Rating level: \textit{low}

Effort multiplier: 1,09 
 
The team members live in different cities and, during the project, had to communicate using individual phones or Social Networks. 
 
\item Required Development Schedule (SCED) 

Rating level: \textit{nominal}

Effort multiplier: 1,00 
 
The time scheduled for planning activities has been fully used in order to develop the RASD and the Design Document.
\end{enumerate}

We define the Effort Adjustment Factor (EAF) as the product of the effort multipliers corresponding to each of the cost drivers for the project. Given the previous cost drivers analysis we can calculate it:

\[EAF= 0.92 * 0.9 * 0.87 * 1 * 1 * 1 * 1 * 0.87 * 0.85 * 0.88 * 0.81 * 1.22 * 1.19 * 1 * 1 * 1.09 * 1 = 0.601\]
 
\section{Effort computation}
 In order to compute the effort we need to know the KSLOC. This is a rather trivial computation since we already know the actual size of the project (see section 2). 
\[KSLOC = \frac{SLOC}{1000} = \frac{4372}{1000} = 4.372\]
 
From the previous sections we know:
\[A=2.94; E=1.0677; EAF=0.601\]

We can now compute the effort as:
\[PM = A * EAF * (KSLOC)E = 2.94 * 0.601 * 4.372^{1.0677} \approx 8,5 (person-month)\]

\section{Effort comparison}
 
COCOMO II treats the number of person-hours per person-month, PH/PM, as an adjustable factor with a nominal value of 152 hours per Person-Month. This number excludes time typically devoted to holidays, vacations, and weekend time off.

If we compute the number of \textit{person-hours} corresponding to the computed effort we obtain:

\[PH = 152 * 8.5 = 1292(person-hours)\]

The time the team actually devoted to the project is 425 hours.
The estimation is three times the real time. This may be due to the fact that COCOMO II has been developed to deal with big projects and teams. In this case, given that the team was made of just two members, we could avoid all the time required to cooperate with many other people. The avoidance of this overhead made the process quicker and can partially explain the overestimation. 


\end{document}